# lightning.pytorch==2.4.0
seed_everything: 10
trainer:
  accelerator: auto
  strategy: auto
  devices: [3]
  num_nodes: 1
  precision: null
  logger: true
  callbacks: null
  fast_dev_run: false
  max_epochs: 300
  min_epochs: 0
  max_steps: -1
  min_steps: null
  max_time: null
  limit_train_batches: null
  limit_val_batches: null
  limit_test_batches: null
  limit_predict_batches: null
  overfit_batches: 0.0
  val_check_interval: null
  check_val_every_n_epoch: 1
  num_sanity_val_steps: 2
  log_every_n_steps: 10
  enable_checkpointing: null
  enable_progress_bar: null
  enable_model_summary: null
  accumulate_grad_batches: 8
  gradient_clip_val: null
  gradient_clip_algorithm: null
  deterministic: true
  benchmark: null
  inference_mode: true
  use_distributed_sampler: true
  profiler: null
  detect_anomaly: false
  barebones: false
  plugins: null
  sync_batchnorm: false
  reload_dataloaders_every_n_epochs: 0
  default_root_dir: experiments/MPRNet
ckpt_path: C:\Users\yxq\project\PL\LitCLI\experiments\MPRNet\lightning_logs\version_0\checkpoints\epoch=77-val_psnr=37.0289.ckpt
model: 
  class_path: IRLitModule
  init_args:
    net: 
      class_path: MPRNet
      init_args:
        in_c: 1
        out_c: 1
    losses:
      class_path: CharbonnierLoss
    psnr:
      class_path: PeakSignalNoiseRatio
    ssim:
      class_path: StructuralSimilarityIndexMeasure
      init_args:
        data_range: 1.0
    optimizer:
      class_path: AdamW
      init_args:
        lr: 2e-4
        weight_decay: 0.
        betas: [0.9, 0.9]
    scheduler:
      # class_path: CosineAnnealingLR
      # init_args:
      #   T_max: 300000
      #   eta_min: 1e-7
      class_path: CosineAnnealingWarmRestarts
      init_args:
        T_0: 300000
        T_mult: 2
        eta_min: 1e-7
    lr_scheduler_config:
      interval: step
      frequency: 1
      # monitor: val_loss
      strict: true
      name: null
data: 
  class_path: IRLitDataModule
  init_args:
    train:
      dataset:
        flag: 0   # 0: grayscale, 1: color, -1: unchanged
        lq_dir: ..\datasets\train\DUKE\lq256.lmdb
        gt_dir: ..\datasets\train\DUKE\gt256.lmdb
      dataloader:
        batch_size: 4
        pin_memory: true
        shuffle: true
        drop_last: true
    val:
      dataset:
        flag: 0
        lq_dir: ..\datasets\val\DUKE\lq512.lmdb
        gt_dir: ..\datasets\val\DUKE\gt512.lmdb
      dataloader:
        batch_size: 1
        pin_memory: true
        shuffle: false
        drop_last: false
    test:
      - dataset:
          flag: 0
          lq_dir: ..\datasets\val\DUKE\lq.lmdb
          gt_dir: ..\datasets\val\DUKE\gt.lmdb
          patch_size: [1200, 1400]
        dataloader:
          batch_size: 1
          pin_memory: true
          shuffle: false
          drop_last: false
    predict:
      dataset:
        flag: 0
        dir: ..\datasets\val\DUKE\lq512
      dataloader:
        batch_size: 1
        pin_memory: true
        shuffle: false
        drop_last: false

